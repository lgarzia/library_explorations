# Summary
Simple to use vector embedding database; in memory or client-server. 
# Resources
`pip install chromadb`
[Chroma Getting Started](https://docs.trychroma.com/getting-started)
https://docs.trychroma.com/embeddings


[Medium Tutorial - Semantic Search](https://medium.com/ai-science/build-semantic-search-applications-using-open-source-vector-database-chromadb-a15e9e7f14ce)
ChromaDB gives us a tool to perform the following functions:

Store embeddings and their metadata with ids.
Embed documents and queries
Search embeddings
So far we have used the default embedding model for the vectorization of input texts but ChromaDB allows various other models from the sentence transformer library as well.

ChromaDB supports many AI models from different embedding providers, such as OpenAI, Sentence transformers, Cohere, and the Google PaLM API. Letâ€™s look at some of them here.
https://www.sbert.net/docs/pretrained_models.html


[Venture Capitalist Read](https://medium.com/memory-leak/our-investment-in-chroma-the-developer-centric-embedding-database-34277ac327e8)
We are currently in the third wave of ML infrastructure. Software engineers have become ML creators massively increasing the number of practitioners, and foundational models have significantly lowered the barrier to adopt ML.

A critical layer in the AI stack is the embedding database, a database built from the ground up around the ML workflow with embeddings. 
We believe a new developer-centric AI stack will emerge to enable the creation of awe-inspiring applications. Winning ML solutions will focus on optimizing the end user experience with ease of use, ergonomics, and performance in mind.